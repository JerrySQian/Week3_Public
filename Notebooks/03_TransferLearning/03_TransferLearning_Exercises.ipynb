{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful libraries        (note: don't forget to turn on GPU)\n",
    "\n",
    "# tensorflow for network building/training\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import Model, Sequential\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# Basic operating system (os), numerical, and plotting functionality\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "\n",
    "# scikit-learn data utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Color transformations\n",
    "from skimage.color import rgb2lab\n",
    "\n",
    "#Skimage resizing \n",
    "from skimage.transform import resize\n",
    "\n",
    "# Garbage collection (for saving RAM during training)\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50 Model\n",
    "\n",
    "For this exercise you'll now use the ResNet50 model as the feature extractor. https://www.tensorflow.org/api_docs/python/tf/keras/applications/ResNet50\n",
    "\n",
    "Specifications:\n",
    "- Expected input size: 244x244 pixels\n",
    "- Output classes: optional # of classes to classify images into, only to be specified if `include_top` is `True`, and if no weights argument is specified\n",
    "\n",
    "Our images are 150x150 pixels in size and come from only 10 categories. In order to use this model for our classification task, we again need to do the following:\n",
    "* Resize images : Our input images can be resized to the appropriate dimensions. Alternatively, we can pad our images to the expected dimensions. Padding leads to additional choices - Do we pad with zeros, duplicate edge pixels or mirror the image across edges?\n",
    "* Change the prediction layer : Remove the existing prediction layer and add a new layer that can predict 8 classes.\n",
    "* Train : Finally, we need to train the network on our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "***Note: for the exercise in this section you'll have to edit a line of code in a line of the cell for resizing images***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting path and changing directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the current directory and the directory where the files to download can\n",
    "# be found\n",
    "current_dir = os.getcwd()\n",
    "remote_path = 'https://github.com/BeaverWorksMedlytics2020/Data_Public/raw/master/NotebookExampleData/Week3/data_nuclei/crc/'\n",
    "\n",
    "# Define and build a directory to save this data in\n",
    "data_dir = os.path.join(current_dir, 'crc_data')\n",
    "if not os.path.isdir(data_dir):\n",
    "  os.mkdir(data_dir)\n",
    "\n",
    "# Move into the data directory and download all of the files\n",
    "os.chdir(data_dir)\n",
    "for ii in range(1, 6):\n",
    "    basename = f'rgb0{ii}.npz'\n",
    "    filename = os.path.join(remote_path, basename)\n",
    "\n",
    "    # Check if the file has already been downloaded\n",
    "    if not os.path.isfile(basename):\n",
    "      cmd = f'wget {filename}'\n",
    "      print(cmd)\n",
    "      os.system(cmd)\n",
    "\n",
    "# Return to the original directory\n",
    "os.chdir(current_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for loading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to load the data from the assumed download path\n",
    "def load_images(colorspace='rgb'):\n",
    "    \"\"\"\n",
    "    Loads the example data and applies transformation into requested colorspace\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    colorspace : str, optional, default: `rgb`\n",
    "        The colorspace into which the images should be transformed. Accepted\n",
    "        values include\n",
    "\n",
    "        'rgb' : Standard red-green-blue color-space for digital images\n",
    "\n",
    "        'gray' or 'grey': An arithmetic average of the (r, g, b) values\n",
    "\n",
    "        'lab': The CIE L*a*b* colorspace\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    images : numpy.ndarray, shape (Nimg, Ny, Nx, Ncolor)\n",
    "        The complete set of transformed images\n",
    "\n",
    "    labels : numpy.ndarray, shape (Nimg)\n",
    "        The classification labels associated with each entry in `images`\n",
    "\n",
    "    label_to_str : dict\n",
    "        A dictionary which converts the numerical classification value in\n",
    "        `labels` into its string equivalent representation.\n",
    "    \"\"\"\n",
    "    # Check that the colorspace argument is recognized\n",
    "    colorspace_lower = colorspace.lower()\n",
    "    if colorspace_lower not in ['rgb', 'gray', 'grey', 'lab']:\n",
    "        raise ValueError(f'`colorspace` value of {colorspace} not recognized')\n",
    "\n",
    "    # Load data, which is stored as a numpy archive file (.npz)\n",
    "    filename = os.path.join(data_dir, 'rgb01.npz')\n",
    "    print(f'loading {filename}')\n",
    "    tmp = np.load(os.path.join(data_dir, 'rgb01.npz'), allow_pickle=True)\n",
    "\n",
    "    # Parse the loaded data into images and labels\n",
    "    # Initialize the images and labels variables using the first archive data\n",
    "    images = tmp['rgb_data']\n",
    "    if colorspace_lower == 'rgb':\n",
    "        pass\n",
    "    elif colorspace_lower in ['gray', 'grey']:\n",
    "        images = np.mean(images, axis=-1)      # Average into grayscale\n",
    "    elif colorspace_lower == 'lab':\n",
    "        images = rgb2lab(images)               # Convert to CIE L*a*b*\n",
    "\n",
    "    # Grab the initial array for the image labels\n",
    "    labels = tmp['labels']\n",
    "    \n",
    "    # Grab the dictionary to convert numerical labels to their string equivalent\n",
    "    label_to_str = tmp['label_str']\n",
    "    label_to_str = label_to_str.tolist() # Convert label_to_str into a dict\n",
    "\n",
    "    # Update the user on the number and size of images loaded\n",
    "    print('Loaded images with shape {}'.format(images.shape))\n",
    "    del tmp\n",
    "\n",
    "    # Loop over each of the remaining archives and append the contained data\n",
    "    for ii in range(2,6):\n",
    "        # Build the full path to the archive and load it into memory\n",
    "        filename = os.path.join(data_dir, f'rgb0{ii}.npz')\n",
    "        print(f'loading {filename}')\n",
    "        tmp = np.load(filename, allow_pickle=True)\n",
    "\n",
    "        # Parse and append the data\n",
    "        these_images = tmp['rgb_data']\n",
    "        if colorspace_lower == 'rgb':\n",
    "            pass\n",
    "        elif (colorspace_lower == 'gray') or (colorspace_lower == 'grey'):\n",
    "            these_images = np.mean(these_images, axis=-1) # Convert to grayscale\n",
    "        elif colorspace_lower == 'lab':\n",
    "            these_images = rgb2lab(these_images)          # Convert to CIEL*a*b*\n",
    "\n",
    "        # Append the images and labels\n",
    "        images = np.append(images, these_images, axis=0)\n",
    "        labels = np.append(labels, tmp['labels'], axis=0)\n",
    "\n",
    "        # Update the user on the number and size of images\n",
    "        print('Loaded images with shape {}'.format(these_images.shape))\n",
    "        del tmp\n",
    "\n",
    "    # Force the image data to be floating point and print the data shape\n",
    "    images = images.astype(np.float)\n",
    "    print('Final image data shape: {}'.format(images.shape))\n",
    "    print('Number of image labels: {}'.format(*labels.shape))\n",
    "\n",
    "    return images, labels, label_to_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load images and labels into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, label_to_str = load_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resizing (remember we want 224x224 pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_images_bool = True\n",
    "num_images = len(images)\n",
    "if scale_images_bool:\n",
    "    # Resize data\n",
    "    ## YOUR CODE HERE\n",
    "    for ii in range(0, num_images):\n",
    "        if not np.mod(ii,1000):\n",
    "            print(f'iter {ii}')\n",
    "        resized_data[ii,::] = resize(images[ii,::], (224, 224, 3), mode='symmetric')\n",
    "    images = resized_data\n",
    "    resized_data = []\n",
    "    print(images.shape)\n",
    "    with open('resized_224.npz', 'wb') as fp:\n",
    "        np.savez(fp, data=images, labels=labels)\n",
    "else:\n",
    "    print('no image scaling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#images.astype(np.float16)\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=.2)\n",
    "\n",
    "# Print sizes of test/train sets\n",
    "print(f'train_images.shape: {train_images.shape}')\n",
    "print(f'train_labels.shape: {train_labels.shape}')\n",
    "print(f'test_images.shape: {test_images.shape}')\n",
    "print(f'test_labels.shape: {test_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale image values to the range of 0->1 (if it hasn't been done already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, we cast image data as float16 to save RAM\n",
    "if train_images[0,::].max() >1:\n",
    "    train_images = train_images.astype(np.float16)/255.\n",
    "if test_images[0,::].max() >1:\n",
    "    test_images = test_images.astype(np.float16)/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting 'labels' (1D array of integers) to onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot pocket\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
    "test_labels = tf.keras.utils.to_categorical(test_labels)\n",
    "\n",
    "print('onehot-encoded labels:')\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-trained ResNet50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base pre-trained model\n",
    "base_model = None\n",
    "model = None\n",
    "print('loading ResNet50')\n",
    "base_model = ## YOUR CODE HERE\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarize model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the pre-trained ResNet50 network by adding a few new layers at the output, including a classification layer (remember we want to predict 8 different classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = base_model.output\n",
    "\n",
    "# Add a global spatial average pooling layer\n",
    "## YOUR CODE HERE\n",
    "\n",
    "# Add a fully-connected layer\n",
    "## YOUR CODE HERE\n",
    "\n",
    "# Add the final classification layer\n",
    "predictions = tf.keras.layers.Dense(## YOUR CODE HERE)\n",
    "\n",
    "# Make the model you will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Print summary of model layers\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freezing layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play around with freezing layers, take a look at the tutorial notebook for reference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model (should be done *after* setting layers to non-trainable)\n",
    "    # optimizer: adam\n",
    "    # loss: categorical crossentropy\n",
    "    # metrics: accuracy\n",
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model on the new data for a few epochs\n",
    "# See how long the model took to train\n",
    "\n",
    "#This function is called after each epoch\n",
    "#(It will ensure that your training process does not consume all available RAM)\n",
    "class garbage_collect_callback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    gc.collect()\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "print('starting model training')\n",
    "history = model.fit(train_images,\n",
    "                    train_labels, \n",
    "                    batch_size=32, \n",
    "                    epochs=40, \n",
    "                    verbose=1, \n",
    "                    validation_data=(test_images, test_labels),\n",
    "                    callbacks = [garbage_collect_callback()])\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot model train/validation accuracy and model train/validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions for Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict class of test images\n",
    "predict = model.predict(test_images, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a set of test images, along with predicted labels and true labels\n",
    "\n",
    "print(predict.shape)\n",
    "id = np.argmax(predict, axis=1)\n",
    "print(id.shape)\n",
    "print(id[0])\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for ii in range(0, 16):\n",
    "    plt.subplot(4,4,ii+1)\n",
    "    plt.imshow(test_images[ii+100,:,:,:].astype(np.float32))\n",
    "    plt.axis('off')\n",
    "    plt.title('expected : ' + label_to_str[np.argmax(test_labels[ii+100])]\n",
    "              + '\\npredicted : ' + label_to_str[id[ii+100]])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
